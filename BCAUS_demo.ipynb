{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from model import BCaus\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "This notebook reproduces the In-Sample and Out-of-Sample Epsilon-ATE values for the BCAUS DR model reported in Table 1 of our manuscript \"Minimizing Bias in Massive Multi-Arm Observational Studies with BCAUS: Balancing Covariates Automatically Using Supervision\".\n",
    "The IHDP benchmark datasets are available online at:\n",
    "1. Train 672 samples: http://www.fredjo.com/files/ihdp_npci_1-1000.train.npz.zip \n",
    "2. Hold-out 75 samples: http://www.fredjo.com/files/ihdp_npci_1-1000.test.npz.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to obtain data locally\n",
    "train_cv = np.load('ihdp_npci_1-1000.train.npz')\n",
    "test = np.load('ihdp_npci_1-1000.test.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, idx=None):\n",
    "    \"\"\"\n",
    "    This function cleans up the data and optionally splits it into train and cv datasets\n",
    "    \"\"\"\n",
    "    X = data.f.x.copy()\n",
    "    T = data.f.t.copy()\n",
    "    YF = data.f.yf.copy()\n",
    "    YCF = data.f.ycf.copy()\n",
    "    X[:,13,:]= X[:,13,:]-1  # Because in the raw data this categorical takes values 1,2 instead of 0,1\n",
    "    if idx is None:\n",
    "        return X, T, YF, YCF\n",
    "    else:\n",
    "        Xtrain = X[:idx,:,:]\n",
    "        Xcv = X[idx:,:,:]\n",
    "\n",
    "        Ttrain = T[:idx,:]\n",
    "        Tcv = T[idx:,:]\n",
    "\n",
    "        YFtrain = YF[:idx,:]\n",
    "        YFcv = YF[idx:,:]\n",
    "\n",
    "        YCFtrain = YCF[:idx,:]\n",
    "        YCFcv = YCF[idx:,:]\n",
    "        \n",
    "        return Xtrain, Ttrain, YFtrain, YCFtrain, Xcv, Tcv, YFcv, YCFcv        \n",
    "\n",
    "def train_instance(X, T, YF, YCF, bcaus, idx=0):\n",
    "    \"\"\"\n",
    "    This function trains BCAUS and DR Estimators on a single instance of IHDP\n",
    "    \"\"\"\n",
    "    x, t, yf, ycf = X[:,:,idx], T[:,idx], YF[:,idx], YCF[:, idx]\n",
    "    \n",
    "    # BCAUS is implemented in the style of a scikit-learn classifier.\n",
    "    bcaus.fit(x,t)\n",
    "    \n",
    "    treated_idx=np.where(t==1)[0]\n",
    "    control_idx=np.where(t==0)[0]\n",
    "    \n",
    "    # Fit estimators for DR\n",
    "    params={\"alpha\":[0.001,0.01,0.1]}\n",
    "    estimator_t = GridSearchCV(Ridge(), param_grid=params, cv=3, n_jobs=3)\n",
    "    estimator_c = GridSearchCV(Ridge(), param_grid=params, cv=3, n_jobs=3)\n",
    "    estimator_t.fit(x[treated_idx,:], yf[treated_idx])\n",
    "    estimator_c.fit(x[control_idx,:], yf[control_idx])\n",
    "    \n",
    "    return bcaus, estimator_t, estimator_c\n",
    "\n",
    "def infer_instance(X, T, YF, YCF, bcaus, estimator_t, estimator_c, idx=0):\n",
    "    \"\"\"\n",
    "    This function infers previously trained BCAUS and DR Estimators on a single instance of IHDP\n",
    "    \"\"\"\n",
    "    x, t, yf, ycf = X[:,:,idx], T[:,idx], YF[:,idx], YCF[:, idx]\n",
    "    \n",
    "    scores = bcaus.predict_proba(x)[:,1]\n",
    "    weights = (t / scores + (1 - t) / (1 - scores))\n",
    "    \n",
    "    treated_idx=np.where(t==1)[0]\n",
    "    control_idx=np.where(t==0)[0]\n",
    "    \n",
    "    treatment_yf_pred= estimator_t.predict(x[treated_idx,:])\n",
    "    treatment_ycf_pred = estimator_c.predict(x[treated_idx,:])\n",
    "    control_yf_pred = estimator_c.predict(x[control_idx,:])\n",
    "    control_ycf_pred = estimator_t.predict(x[control_idx,:])\n",
    "\n",
    "    treatment_ite = (yf[treated_idx]/scores[treated_idx]\n",
    "                        -treatment_yf_pred*(1-scores[treated_idx])/scores[treated_idx]\n",
    "                        -treatment_ycf_pred)\n",
    "    control_ite = control_ycf_pred-(yf[control_idx]/(1-scores[control_idx])\n",
    "                                    -control_yf_pred*scores[control_idx]/(1-scores[control_idx]))\n",
    "    \n",
    "    est_ate = np.mean(np.array(list(treatment_ite)+list(control_ite)))\n",
    "    \n",
    "    Y1 = np.array(list(yf[treated_idx]) + list(ycf[control_idx]))\n",
    "    Y0 = np.array(list(ycf[treated_idx]) + list(yf[control_idx]))\n",
    "    \n",
    "    gt_ate = np.mean(Y1)-np.mean(Y0)\n",
    "    \n",
    "    return est_ate, gt_ate  \n",
    "\n",
    "def computeEpsilons(Xtrain, Ttrain, YFtrain, YCFtrain, Xcv, Tcv, YFcv, YCFcv, bcaus):\n",
    "    \"\"\"\n",
    "    This function computes Epsilon-ATE and standard error on train and cv/test sets on all 1000 \n",
    "    instances of IHDP\n",
    "    \"\"\"\n",
    "    niters = Xtrain.shape[-1]\n",
    "    \n",
    "    gt_train=[]  # Ground Truth\n",
    "    est_train=[] # Estimated\n",
    "    gt_cv=[]     # Ground Truth\n",
    "    est_cv=[]    # Estimated\n",
    "\n",
    "    for fnum in range(niters): \n",
    "        \n",
    "        bcaus, estimator_t, estimator_c = train_instance(Xtrain, Ttrain, YFtrain, YCFtrain, bcaus, idx = fnum)\n",
    "        \n",
    "        ate1, gt1 =  infer_instance(Xtrain, Ttrain, YFtrain, YCFtrain, bcaus, estimator_t, estimator_c, idx=fnum)\n",
    "        est_train.append(ate1)\n",
    "        gt_train.append(gt1)\n",
    "        \n",
    "        ate1, gt1 =  infer_instance(Xcv, Tcv, YFcv, YCFcv, bcaus, estimator_t, estimator_c, idx=fnum)\n",
    "        est_cv.append(ate1)\n",
    "        gt_cv.append(gt1)\n",
    "\n",
    "        if (fnum+1)%1000==0:\n",
    "            print('Instance %d finished!'%(fnum))\n",
    "        \n",
    "    # Train error\n",
    "    abs_error = np.abs(np.array(gt_train)-np.array(est_train))\n",
    "    in_eps_ate= np.mean(abs_error)\n",
    "    in_err = scipy.stats.sem(abs_error)\n",
    "\n",
    "    # CV error\n",
    "    abs_error = np.abs(np.array(gt_cv)-np.array(est_cv))\n",
    "    cv_eps_ate= np.mean(abs_error)\n",
    "    cv_err = scipy.stats.sem(abs_error)\n",
    "    \n",
    "    return in_eps_ate, in_err, cv_eps_ate, cv_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training data into train and cross validation sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 1000) (172, 1000)\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Ttrain, YFtrain, YCFtrain, Xcv, Tcv, YFcv, YCFcv = split_data(train_cv, 500)\n",
    "print(YCFtrain.shape, YCFcv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance 999 finished!\n",
      "Instance 999 finished!\n",
      "Instance 999 finished!\n",
      "Instance 999 finished!\n",
      "Instance 999 finished!\n",
      "Instance 999 finished!\n",
      "Instance 999 finished!\n",
      "Instance 999 finished!\n",
      "Instance 999 finished!\n",
      "Instance 999 finished!\n",
      "Instance 999 finished!\n",
      "Instance 999 finished!\n",
      "Instance 999 finished!\n",
      "Instance 999 finished!\n",
      "Instance 999 finished!\n",
      "Instance 999 finished!\n",
      "Instance 999 finished!\n",
      "Instance 999 finished!\n",
      "Instance 999 finished!\n",
      "Instance 999 finished!\n",
      "Instance 999 finished!\n",
      "Instance 999 finished!\n",
      "Instance 999 finished!\n",
      "Instance 999 finished!\n"
     ]
    }
   ],
   "source": [
    "alpha=[0.001, 0.01]\n",
    "dropout=[0.1, 0.3 ,0.5]\n",
    "learning_rate_init = [0.001]\n",
    "nu=[0.0, 0.5, 1, 1.5]\n",
    "\n",
    "grid_df=pd.DataFrame({\"alpha\":[],\n",
    "                     \"dropout\":[],\n",
    "                     \"learning_rate_init\":[],\n",
    "                     \"nu\":[],\n",
    "                     \"train_sample_dr\":[], \n",
    "                     \"cv_sample_dr\":[]})\n",
    "\n",
    "for a, d, lr, n in itertools.product(alpha,dropout, learning_rate_init, nu):\n",
    "    grid_params={\"alpha\":a, \"dropout\":d, \"learning_rate_init\": lr, \"nu\":n}\n",
    "\n",
    "    bcaus=BCaus(device='cuda:7', early_stopping=True, eps=1e-07, max_iter=1000, n_iter_no_change=30, **grid_params)\n",
    "    train_eps_ate, _, cv_eps_ate, _ = computeEpsilons(Xtrain, Ttrain, YFtrain, YCFtrain, Xcv, Tcv, YFcv, YCFcv, bcaus)\n",
    "\n",
    "    grid_params.update({\"train_sample_dr\":train_eps_ate, \"cv_sample_dr\":cv_eps_ate})\n",
    "    grid_df = grid_df.append(grid_params, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df = grid_df.sort_values('cv_sample_dr').reset_index(drop = True)\n",
    "best_params = grid_df.iloc[0,:4].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on hold-out set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance 999 finished!\n"
     ]
    }
   ],
   "source": [
    "X_in, T_in, YF_in, YCF_in = split_data(train_cv)\n",
    "X_oo, T_oo, YF_oo, YCF_oo = split_data(test)\n",
    "\n",
    "bcaus=BCaus(device='cuda:7', early_stopping=True, eps=1e-07, max_iter=1000, n_iter_no_change=30, **best_params)\n",
    "in_eps_ate, in_err, oo_eps_ate, oo_err = computeEpsilons(X_in, T_in, YF_in, YCF_in, X_oo, T_oo, YF_oo, YCF_oo, bcaus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-Sample Epsilon ATE = 0.13212367321365898 +/- 0.004395004517373404\n",
      "Out-of-Sample Epsilon ATE = 0.29538274983277246 +/- 0.011989530664810202\n"
     ]
    }
   ],
   "source": [
    "print('In-Sample Epsilon ATE = {} +/- {}'.format(in_eps_ate, in_err))\n",
    "print('Out-of-Sample Epsilon ATE = {} +/- {}'.format(oo_eps_ate, oo_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal",
   "language": "python",
   "name": "causal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
